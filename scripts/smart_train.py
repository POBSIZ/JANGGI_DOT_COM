#!/usr/bin/env python3
"""Smart NNUE Training Script - ìë™ í™˜ê²½ ê°ì§€ ë° ìµœì í™” í•™ìŠµ.

ì»´í“¨í„° í™˜ê²½ì„ ìë™ìœ¼ë¡œ íŒŒì•…í•˜ì—¬ ìµœì ì˜ í•™ìŠµ ë°©ì‹ì„ ì„ íƒí•©ë‹ˆë‹¤.
í•™ìŠµ ì‹œê°„ì„ ì„ íƒí•˜ë©´ í•´ë‹¹ ì‹œê°„ì— ë§ëŠ” ì„¤ì •ìœ¼ë¡œ ìë™ í•™ìŠµí•©ë‹ˆë‹¤.

Usage:
    # ëŒ€í™”í˜• ëª¨ë“œ (ê¶Œì¥)
    python smart_train.py
    
    # ì§ì ‘ ì‹œê°„ ì„ íƒ
    python smart_train.py --time quick       # ~5ë¶„
    python smart_train.py --time standard    # ~15ë¶„  
    python smart_train.py --time deep        # ~30ë¶„
    python smart_train.py --time intensive   # ~1ì‹œê°„
    python smart_train.py --time full        # ~3ì‹œê°„ (ê°•í™”ëœ ì„¤ì •)
    python smart_train.py --time extreme     # ~4ì‹œê°„ (ìµœê°• ì„±ëŠ¥)
    python smart_train.py --time marathon    # ~8ì‹œê°„ (ìµœì¢… ë³´ìŠ¤)
    
    # ê¸°ì¡´ ëª¨ë¸ì—ì„œ ê³„ì† í•™ìŠµ
    python smart_train.py --load models/nnue_model.json --time standard
"""

import argparse
import os
import sys
import platform
import time
import glob
import multiprocessing as mp
from typing import Dict, Tuple, Optional, Any
from dataclasses import dataclass
from enum import Enum

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ============================================================================
# Configuration Constants
# ============================================================================

# System Requirements
MIN_CPU_CORES_FOR_PARALLEL = 4
MIN_RAM_GB = 8
MIN_GIBO_FILES_FOR_TRAINING = 5
MAX_WORKERS = 8
MIN_WORKERS_LOW_RAM = 2

# GPU Memory Thresholds (GB)
GPU_MEMORY_HIGH = 8
GPU_MEMORY_MEDIUM = 4

# Time Adjustment Factors
GPU_TIME_REDUCTION_FULL_MODE = 0.7
GPU_TIME_REDUCTION_NORMAL_MODE = 0.5
CPU_POSITION_REDUCTION_LOW_CORES = 0.7
RAM_POSITION_REDUCTION = 0.5

# Position Scaling Factors
GPU_POSITION_SCALE_HIGH_MEMORY_FULL = 2.0
GPU_POSITION_SCALE_HIGH_MEMORY_NORMAL = 1.5
GPU_POSITION_SCALE_MEDIUM_MEMORY = 1.5

# Time Estimation Constants (seconds per unit)
# í¬ì§€ì…˜ ìƒì„± ì‹œê°„ (ì´ˆ/í¬ì§€ì…˜)
POSITION_GEN_TIME_CPU_SINGLE = 0.01      # CPU ë‹¨ì¼ ìŠ¤ë ˆë“œ
POSITION_GEN_TIME_CPU_PARALLEL = 0.003   # CPU ë³‘ë ¬ (ì›Œì»¤ë‹¹)
POSITION_GEN_TIME_GPU = 0.001            # GPU ê°€ì†
DEPTH_TIME_MULTIPLIER = 1.5              # ê¹Šì´ë‹¹ ì‹œê°„ ë°°ìˆ˜

# í•™ìŠµ ì‹œê°„ (ì´ˆ/ì—í¬í¬/1000í¬ì§€ì…˜)
TRAINING_TIME_CPU_PER_1K = 2.0           # CPU: 1000í¬ì§€ì…˜ë‹¹ 2ì´ˆ/ì—í¬í¬
TRAINING_TIME_GPU_PER_1K = 0.3           # GPU: 1000í¬ì§€ì…˜ë‹¹ 0.3ì´ˆ/ì—í¬í¬
BATCH_SIZE_EFFICIENCY = {                # ë°°ì¹˜ ì‚¬ì´ì¦ˆë³„ íš¨ìœ¨
    64: 1.0,
    128: 0.9,
    256: 0.8,
    512: 0.7,
    1024: 0.6
}

# ê¸°ë³´ ì²˜ë¦¬ ì‹œê°„
GIBO_PARSE_TIME_PER_GAME = 0.01         # ê²Œì„ë‹¹ íŒŒì‹± ì‹œê°„ (ì´ˆ)
GIBO_PROCESS_TIME_PER_POSITION = 0.0005  # í¬ì§€ì…˜ë‹¹ ì²˜ë¦¬ ì‹œê°„ (ì´ˆ)

# ë°˜ë³µ í•™ìŠµ ì˜¤ë²„í—¤ë“œ
ITERATION_OVERHEAD = 1.1                # ë°˜ë³µë‹¹ 10% ì˜¤ë²„í—¤ë“œ


class TrainingTime(Enum):
    """í•™ìŠµ ì‹œê°„ ì˜µì…˜"""
    QUICK = "quick"           # ~5ë¶„
    STANDARD = "standard"     # ~15ë¶„
    DEEP = "deep"             # ~30ë¶„
    INTENSIVE = "intensive"   # ~1ì‹œê°„
    FULL = "full"             # ~2ì‹œê°„+
    EXTREME = "extreme"       # ~4ì‹œê°„+
    MARATHON = "marathon"     # ~8ì‹œê°„+


@dataclass
class SystemInfo:
    """ì‹œìŠ¤í…œ ì •ë³´"""
    os_name: str
    cpu_name: str
    cpu_cores: int
    cpu_threads: int
    ram_gb: float
    gpu_available: bool
    gpu_type: str  # 'cuda', 'mps', 'none'
    gpu_name: str
    gpu_memory_gb: float
    has_gibo_files: bool
    gibo_file_count: int
    gpu_error_message: Optional[str] = None


@dataclass
class TrainingConfig:
    """í•™ìŠµ ì„¤ì •"""
    method: str  # 'gpu', 'cpu', 'gibo', 'hybrid'
    positions: int
    epochs: int
    batch_size: int
    learning_rate: float
    search_depth: int
    iterations: int  # for iterative training
    use_parallel: bool
    num_workers: int
    use_gibo: bool
    use_hybrid: bool  # Phase 3: í˜¼í•© í•™ìŠµ ì‚¬ìš© ì—¬ë¶€
    estimated_time_min: int


def get_system_info(gibo_dir: str = "gibo") -> SystemInfo:
    """ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘"""
    import multiprocessing
    import subprocess
    
    # OS ì •ë³´
    os_name = f"{platform.system()} {platform.release()}"
    
    # CPU ì •ë³´
    cpu_name = platform.processor() or "Unknown CPU"
    cpu_cores = multiprocessing.cpu_count()
    
    # ë¬¼ë¦¬ì  ì½”ì–´ vs ë…¼ë¦¬ì  ìŠ¤ë ˆë“œ
    try:
        import psutil
        cpu_threads = psutil.cpu_count(logical=True)
        cpu_cores_physical = psutil.cpu_count(logical=False) or cpu_cores
    except ImportError:
        cpu_threads = cpu_cores
        cpu_cores_physical = cpu_cores
    
    # RAM ì •ë³´
    try:
        import psutil
        ram_gb = psutil.virtual_memory().total / (1024 ** 3)
    except ImportError:
        # macOSì—ì„œ sysctl ì‚¬ìš©
        try:
            if platform.system() == "Darwin":
                result = subprocess.run(
                    ["sysctl", "-n", "hw.memsize"],
                    capture_output=True, text=True
                )
                ram_gb = int(result.stdout.strip()) / (1024 ** 3)
            elif platform.system() == "Linux":
                with open("/proc/meminfo", "r") as f:
                    for line in f:
                        if line.startswith("MemTotal:"):
                            ram_kb = int(line.split()[1])
                            ram_gb = ram_kb / (1024 ** 2)
                            break
            else:
                ram_gb = 8.0  # ê¸°ë³¸ê°’
        except:
            ram_gb = 8.0  # ê¸°ë³¸ê°’
    
    # GPU ì •ë³´
    gpu_available = False
    gpu_type = "none"
    gpu_name = "None"
    gpu_memory_gb = 0.0
    gpu_error_message = None
    
    try:
        import torch
        # PyTorchê°€ ì„±ê³µì ìœ¼ë¡œ importë˜ì—ˆëŠ”ì§€ í™•ì¸
        if torch.cuda.is_available():
            gpu_available = True
            gpu_type = "cuda"
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)
        elif hasattr(torch.backends, "mps") and torch.backends.mps.is_available():
            gpu_available = True
            gpu_type = "mps"
            gpu_name = "Apple Silicon (MPS)"
            # MPS doesn't report memory directly, estimate based on system
            try:
                import psutil
                # Apple Silicon shares memory with system
                gpu_memory_gb = psutil.virtual_memory().total / (1024 ** 3) * 0.5
            except:
                gpu_memory_gb = 8.0  # Default estimate
        else:
            # PyTorchëŠ” ì„¤ì¹˜ë˜ì–´ ìˆì§€ë§Œ CUDA/MPSë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŒ
            torch_version = torch.__version__
            if "+cpu" in torch_version:
                gpu_error_message = f"PyTorch CPU-only ë²„ì „ì´ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤ ({torch_version}). GPUë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ CUDA ì§€ì› ë²„ì „ì„ ì„¤ì¹˜í•˜ì„¸ìš”:\n  uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
            else:
                gpu_error_message = "PyTorchëŠ” ì„¤ì¹˜ë˜ì–´ ìˆì§€ë§Œ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CUDA ë“œë¼ì´ë²„ê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”."
    except (ImportError, AttributeError, RuntimeError) as e:
        # PyTorch import ì‹¤íŒ¨ ë˜ëŠ” ë‚´ë¶€ ì˜¤ë¥˜ (ì˜ˆ: AcceleratorError ë“±)
        error_type = type(e).__name__
        if isinstance(e, ImportError):
            gpu_error_message = "PyTorchê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. GPUë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ PyTorchë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”:\n  uv sync --extra gpu\në˜ëŠ” CUDA ì§€ì› ë²„ì „:\n  uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
        else:
            # PyTorch ì„¤ì¹˜ê°€ ì†ìƒë˜ì—ˆê±°ë‚˜ í˜¸í™˜ì„± ë¬¸ì œ
            gpu_error_message = f"PyTorch ì„¤ì¹˜ì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤ ({error_type}: {str(e)}).\n  PyTorchë¥¼ ì¬ì„¤ì¹˜í•˜ì„¸ìš”:\n  uv pip install --force-reinstall torch\n  ë˜ëŠ” CUDA ì§€ì› ë²„ì „:\n  uv pip install --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
    
    # ê¸°ë³´ íŒŒì¼ í™•ì¸
    gibo_files = glob.glob(os.path.join(gibo_dir, "*.gib")) + glob.glob(os.path.join(gibo_dir, "*.GIB"))
    has_gibo_files = len(gibo_files) > 0
    gibo_file_count = len(gibo_files)
    
    return SystemInfo(
        os_name=os_name,
        cpu_name=cpu_name,
        cpu_cores=cpu_cores_physical,
        cpu_threads=cpu_threads,
        ram_gb=ram_gb,
        gpu_available=gpu_available,
        gpu_type=gpu_type,
        gpu_name=gpu_name,
        gpu_memory_gb=gpu_memory_gb,
        has_gibo_files=has_gibo_files,
        gibo_file_count=gibo_file_count,
        gpu_error_message=gpu_error_message
    )


def print_system_info(info: SystemInfo):
    """ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥"""
    print("\n" + "=" * 60)
    print("ğŸ–¥ï¸  ì‹œìŠ¤í…œ í™˜ê²½ ë¶„ì„")
    print("=" * 60)
    
    print(f"\nğŸ“Œ ìš´ì˜ì²´ì œ: {info.os_name}")
    print(f"ğŸ“Œ CPU: {info.cpu_name}")
    print(f"   - ì½”ì–´: {info.cpu_cores}ê°œ / ìŠ¤ë ˆë“œ: {info.cpu_threads}ê°œ")
    print(f"ğŸ“Œ RAM: {info.ram_gb:.1f} GB")
    
    if info.gpu_available:
        print(f"ğŸ“Œ GPU: {info.gpu_name} ({'CUDA' if info.gpu_type == 'cuda' else 'MPS'})")
        print(f"   - VRAM: {info.gpu_memory_gb:.1f} GB")
        print("   âœ… GPU ê°€ì† ì‚¬ìš© ê°€ëŠ¥")
    else:
        print("ğŸ“Œ GPU: ì‚¬ìš© ë¶ˆê°€ (CPU í•™ìŠµ ëª¨ë“œ)")
        if info.gpu_error_message:
            print(f"   âš ï¸  {info.gpu_error_message}")
    
    if info.has_gibo_files:
        print(f"ğŸ“Œ ê¸°ë³´ íŒŒì¼: {info.gibo_file_count}ê°œ ë°œê²¬")
        print("   âœ… ê¸°ë³´ ê¸°ë°˜ í•™ìŠµ ê°€ëŠ¥")
    else:
        print("ğŸ“Œ ê¸°ë³´ íŒŒì¼: ì—†ìŒ (self-play í•™ìŠµ)")


def estimate_training_time(
    config: Dict,
    info: SystemInfo,
    use_parallel: bool,
    num_workers: int,
    use_gibo: bool,
    gibo_file_count: int = 0,
    use_hybrid: bool = False
) -> int:
    """í•™ìŠµ ì‹œê°„ì„ ë™ì ìœ¼ë¡œ ê³„ì‚°.
    
    Args:
        config: í•™ìŠµ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        info: ì‹œìŠ¤í…œ ì •ë³´
        use_parallel: ë³‘ë ¬ ì²˜ë¦¬ ì‚¬ìš© ì—¬ë¶€
        num_workers: ì›Œì»¤ ìˆ˜
        use_gibo: ê¸°ë³´ ì‚¬ìš© ì—¬ë¶€
        gibo_file_count: ê¸°ë³´ íŒŒì¼ ìˆ˜
        use_hybrid: í˜¼í•© í•™ìŠµ ì‚¬ìš© ì—¬ë¶€ (Phase 3)
        
    Returns:
        ì˜ˆìƒ ì‹œê°„ (ë¶„)
    """
    positions = config["positions"]
    epochs = config["epochs"]
    batch_size = config["batch_size"]
    depth = config["depth"]
    iterations = config.get("iterations", 1)
    
    total_time = 0.0
    
    # Phase 3: í˜¼í•© í•™ìŠµ ì‹œê°„ ê³„ì‚°
    if use_hybrid and use_gibo and gibo_file_count > 0:
        # í˜¼í•© í•™ìŠµ: ê° iterationë§ˆë‹¤ (ê¸°ë³´ â†’ Self-play â†’ Fine-tuning â†’ í‰ê°€)
        # ê° ë‹¨ê³„ì˜ epoch ìˆ˜ë¥¼ ì ì ˆíˆ ë¶„ë°°
        gibo_epochs = max(1, epochs // (iterations * 4))
        selfplay_epochs = max(5, epochs // (iterations * 2))
        fine_tune_epochs = max(1, epochs // (iterations * 4))
        
        # Self-play ê²Œì„ ìˆ˜
        positions_per_iteration = positions // iterations
        selfplay_games = max(50, positions_per_iteration // 80)
        
        for iteration in range(iterations):
            # Step 1: ê¸°ë³´ í•™ìŠµ
            estimated_gibo_positions = gibo_file_count * 50
            gibo_parse_time = gibo_file_count * GIBO_PARSE_TIME_PER_GAME
            gibo_process_time = estimated_gibo_positions * GIBO_PROCESS_TIME_PER_POSITION
            
            if info.gpu_available:
                gibo_train_time = (estimated_gibo_positions / 1000) * TRAINING_TIME_GPU_PER_1K * gibo_epochs
            else:
                gibo_train_time = (estimated_gibo_positions / 1000) * TRAINING_TIME_CPU_PER_1K * gibo_epochs
            
            batch_efficiency = BATCH_SIZE_EFFICIENCY.get(batch_size, 0.8)
            gibo_train_time *= batch_efficiency
            total_time += gibo_parse_time + gibo_process_time + gibo_train_time
            
            # Step 2: Self-play í•™ìŠµ
            if info.gpu_available:
                pos_gen_time = (selfplay_games * 80) * POSITION_GEN_TIME_GPU
                selfplay_train_time = ((selfplay_games * 80) / 1000) * TRAINING_TIME_GPU_PER_1K * selfplay_epochs
            elif use_parallel and num_workers > 1:
                pos_gen_time = ((selfplay_games * 80) * POSITION_GEN_TIME_CPU_PARALLEL) / num_workers
                selfplay_train_time = ((selfplay_games * 80) / 1000) * TRAINING_TIME_CPU_PER_1K * selfplay_epochs
            else:
                pos_gen_time = (selfplay_games * 80) * POSITION_GEN_TIME_CPU_SINGLE
                selfplay_train_time = ((selfplay_games * 80) / 1000) * TRAINING_TIME_CPU_PER_1K * selfplay_epochs
            
            depth_multiplier = DEPTH_TIME_MULTIPLIER ** (depth - 2)
            pos_gen_time *= depth_multiplier
            selfplay_train_time *= batch_efficiency
            total_time += pos_gen_time + selfplay_train_time
            
            # Step 3: Fine-tuning (ê¸°ë³´ ì¬ì‚¬ìš©)
            if info.gpu_available:
                fine_tune_time = (estimated_gibo_positions / 1000) * TRAINING_TIME_GPU_PER_1K * fine_tune_epochs
            else:
                fine_tune_time = (estimated_gibo_positions / 1000) * TRAINING_TIME_CPU_PER_1K * fine_tune_epochs
            
            fine_tune_time *= batch_efficiency * 0.5  # Fine-tuningì€ ë” ë¹ ë¦„ (ë‚®ì€ LR)
            total_time += fine_tune_time
            
            # Step 4: í‰ê°€ ì‹œê°„ (ê°„ë‹¨íˆ ì¶”ì •)
            eval_time = 10.0  # í‰ê°€ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ë¹ ë¦„
            total_time += eval_time
        
        # í˜¼í•© í•™ìŠµ ì˜¤ë²„í—¤ë“œ
        total_time *= (ITERATION_OVERHEAD ** iterations)
        
        # ì‹œìŠ¤í…œ ì„±ëŠ¥ ë³´ì •
        if not info.gpu_available:
            if info.cpu_cores < 4:
                total_time *= 1.3
            elif info.cpu_cores >= 8:
                total_time *= 0.9
        
        if info.ram_gb < MIN_RAM_GB:
            total_time *= 1.2
        
        if info.gpu_available:
            if info.gpu_memory_gb >= 16:
                total_time *= 0.85
            elif info.gpu_memory_gb < 4:
                total_time *= 1.15
        
        estimated_minutes = max(1, int(total_time / 60))
        return estimated_minutes
    
    # ê¸°ì¡´ í•™ìŠµ ì‹œê°„ ê³„ì‚° (í˜¼í•© í•™ìŠµì´ ì•„ë‹ ë•Œ)
    # 1. ê¸°ë³´ ì²˜ë¦¬ ì‹œê°„ (ìˆëŠ” ê²½ìš°)
    if use_gibo and gibo_file_count > 0:
        # ê¸°ë³´ íŒŒì‹± ì‹œê°„
        gibo_parse_time = gibo_file_count * GIBO_PARSE_TIME_PER_GAME
        
        # ê¸°ë³´ í¬ì§€ì…˜ ì²˜ë¦¬ ì‹œê°„ (í‰ê·  ê²Œì„ë‹¹ 50í¬ì§€ì…˜ ê°€ì •)
        estimated_gibo_positions = gibo_file_count * 50
        gibo_process_time = estimated_gibo_positions * GIBO_PROCESS_TIME_PER_POSITION
        
        # ê¸°ë³´ í•™ìŠµ ì‹œê°„ (ì—í¬í¬ì˜ ì ˆë°˜ ì‚¬ìš©)
        gibo_epochs = epochs // 2
        if info.gpu_available:
            gibo_train_time = (estimated_gibo_positions / 1000) * TRAINING_TIME_GPU_PER_1K * gibo_epochs
        else:
            gibo_train_time = (estimated_gibo_positions / 1000) * TRAINING_TIME_CPU_PER_1K * gibo_epochs
        
        # ë°°ì¹˜ ì‚¬ì´ì¦ˆ íš¨ìœ¨ ì ìš©
        batch_efficiency = BATCH_SIZE_EFFICIENCY.get(batch_size, 0.8)
        gibo_train_time *= batch_efficiency
        
        total_time += gibo_parse_time + gibo_process_time + gibo_train_time
    
    # 2. í¬ì§€ì…˜ ìƒì„± ì‹œê°„
    if iterations > 1:
        # ë°˜ë³µ í•™ìŠµ: ê° ë°˜ë³µë§ˆë‹¤ í¬ì§€ì…˜ ìƒì„±
        positions_per_iter = positions // iterations
        
        for _ in range(iterations):
            if info.gpu_available:
                # GPU: ë¹ ë¥¸ ìƒì„±
                pos_gen_time = positions_per_iter * POSITION_GEN_TIME_GPU
            elif use_parallel and num_workers > 1:
                # CPU ë³‘ë ¬: ì›Œì»¤ ìˆ˜ì— ë¹„ë¡€í•˜ì—¬ ë¹ ë¦„
                pos_gen_time = (positions_per_iter * POSITION_GEN_TIME_CPU_PARALLEL) / num_workers
            else:
                # CPU ë‹¨ì¼: ëŠë¦¼
                pos_gen_time = positions_per_iter * POSITION_GEN_TIME_CPU_SINGLE
            
            # ê¹Šì´ì— ë”°ë¥¸ ì‹œê°„ ì¦ê°€
            depth_multiplier = DEPTH_TIME_MULTIPLIER ** (depth - 2)  # depth 2ë¥¼ ê¸°ì¤€
            pos_gen_time *= depth_multiplier
            
            total_time += pos_gen_time
    else:
        # ë‹¨ì¼ í•™ìŠµ: í•œ ë²ˆë§Œ ìƒì„±
        if info.gpu_available:
            pos_gen_time = positions * POSITION_GEN_TIME_GPU
        elif use_parallel and num_workers > 1:
            pos_gen_time = (positions * POSITION_GEN_TIME_CPU_PARALLEL) / num_workers
        else:
            pos_gen_time = positions * POSITION_GEN_TIME_CPU_SINGLE
        
        # ê¹Šì´ì— ë”°ë¥¸ ì‹œê°„ ì¦ê°€
        depth_multiplier = DEPTH_TIME_MULTIPLIER ** (depth - 2)
        pos_gen_time *= depth_multiplier
        
        total_time += pos_gen_time
    
    # 3. í•™ìŠµ ì‹œê°„
    if iterations > 1:
        # ë°˜ë³µ í•™ìŠµ: ê° ë°˜ë³µë§ˆë‹¤ í•™ìŠµ
        positions_per_iter = positions // iterations
        epochs_per_iter = max(10, epochs // iterations)
        
        for _ in range(iterations):
            if info.gpu_available:
                train_time = (positions_per_iter / 1000) * TRAINING_TIME_GPU_PER_1K * epochs_per_iter
            else:
                train_time = (positions_per_iter / 1000) * TRAINING_TIME_CPU_PER_1K * epochs_per_iter
            
            # ë°°ì¹˜ ì‚¬ì´ì¦ˆ íš¨ìœ¨ ì ìš©
            batch_efficiency = BATCH_SIZE_EFFICIENCY.get(batch_size, 0.8)
            train_time *= batch_efficiency
            
            total_time += train_time
    else:
        # ë‹¨ì¼ í•™ìŠµ
        if info.gpu_available:
            train_time = (positions / 1000) * TRAINING_TIME_GPU_PER_1K * epochs
        else:
            train_time = (positions / 1000) * TRAINING_TIME_CPU_PER_1K * epochs
        
        # ë°°ì¹˜ ì‚¬ì´ì¦ˆ íš¨ìœ¨ ì ìš©
        batch_efficiency = BATCH_SIZE_EFFICIENCY.get(batch_size, 0.8)
        train_time *= batch_efficiency
        
        total_time += train_time
    
    # 4. ë°˜ë³µ í•™ìŠµ ì˜¤ë²„í—¤ë“œ
    if iterations > 1:
        total_time *= (ITERATION_OVERHEAD ** iterations)
    
    # 5. ì‹œìŠ¤í…œ ì„±ëŠ¥ ë³´ì •
    # CPU ì½”ì–´ ìˆ˜ì— ë”°ë¥¸ ë³´ì •
    if not info.gpu_available:
        if info.cpu_cores < 4:
            total_time *= 1.3  # ì €ì‚¬ì–‘ CPU
        elif info.cpu_cores >= 8:
            total_time *= 0.9  # ê³ ì‚¬ì–‘ CPU
    
    # RAM ë¶€ì¡± ì‹œ ëŠë ¤ì§
    if info.ram_gb < MIN_RAM_GB:
        total_time *= 1.2
    
    # GPU ë©”ëª¨ë¦¬ì— ë”°ë¥¸ ë³´ì •
    if info.gpu_available:
        if info.gpu_memory_gb >= 16:
            total_time *= 0.85  # ëŒ€ìš©ëŸ‰ GPUëŠ” ë” ë¹ ë¦„
        elif info.gpu_memory_gb < 4:
            total_time *= 1.15  # ì†Œìš©ëŸ‰ GPUëŠ” ë” ëŠë¦¼
    
    # ì´ˆë¥¼ ë¶„ìœ¼ë¡œ ë³€í™˜ (ìµœì†Œ 1ë¶„)
    estimated_minutes = max(1, int(total_time / 60))
    
    return estimated_minutes


def get_training_config(info: SystemInfo, training_time: TrainingTime, use_gibo: bool = True, method: Optional[str] = None) -> TrainingConfig:
    """ì‹œìŠ¤í…œ í™˜ê²½ê³¼ í•™ìŠµ ì‹œê°„ì— ë”°ë¥¸ ìµœì  ì„¤ì • ê³„ì‚°
    
    Args:
        info: ì‹œìŠ¤í…œ ì •ë³´
        training_time: í•™ìŠµ ì‹œê°„ ì˜µì…˜
        use_gibo: ê¸°ë³´ ì‚¬ìš© ì—¬ë¶€
        method: ì§ì ‘ ì§€ì •í•  í•™ìŠµ ë°©ë²• ('gpu', 'cpu', 'gibo', 'hybrid'). Noneì´ë©´ ìë™ ê°ì§€
    """
    
    # ê¸°ë³¸ ì„¤ì •ê°’ (ì‹œê°„ë³„) - estimated_minì€ ë™ì  ê³„ì‚°ìœ¼ë¡œ ëŒ€ì²´ë¨
    time_configs = {
        TrainingTime.QUICK: {
            "positions": 2000,
            "epochs": 15,
            "batch_size": 128,
            "lr": 0.001,
            "depth": 2,
            "iterations": 1
        },
        TrainingTime.STANDARD: {
            "positions": 10000,  # 2ë°° ì¦ê°€ (ë°˜ë³µ í•™ìŠµ ê³ ë ¤)
            "epochs": 50,        # ì¦ê°€
            "batch_size": 256,
            "lr": 0.001,         # ì•½ê°„ ì¦ê°€
            "depth": 3,          # ê¹Šì´ ì¦ê°€ (ë” ë‚˜ì€ í‰ê°€)
            "iterations": 1      # ë‹¨ì¼ í•™ìŠµìœ¼ë¡œ ë³€ê²½ (ë°˜ë³µ í•™ìŠµì€ ë°ì´í„°ê°€ ë¶€ì¡±í•  ë•Œ ì˜¤íˆë ¤ í•´ë¡œì›€)
        },
        TrainingTime.DEEP: {
            "positions": 10000,
            "epochs": 50,
            "batch_size": 256,
            "lr": 0.0005,
            "depth": 3,
            "iterations": 3
        },
        TrainingTime.INTENSIVE: {
            "positions": 20000,
            "epochs": 80,
            "batch_size": 512,
            "lr": 0.0003,
            "depth": 3,
            "iterations": 5
        },
        TrainingTime.FULL: {
            "positions": 150000,  # 3ë°° ì¦ê°€
            "epochs": 200,        # 2ë°° ì¦ê°€
            "batch_size": 512,
            "lr": 0.0002,
            "depth": 5,           # ê¹Šì´ ì¦ê°€
            "iterations": 15      # ë°˜ë³µ ì¦ê°€
        },
        TrainingTime.EXTREME: {
            "positions": 300000,  # 6ë°° ì¦ê°€
            "epochs": 300,        # 3ë°° ì¦ê°€
            "batch_size": 512,
            "lr": 0.00015,
            "depth": 6,           # ë” ê¹Šì€ íƒìƒ‰
            "iterations": 20      # ë” ë§ì€ ë°˜ë³µ
        },
        TrainingTime.MARATHON: {
            "positions": 500000,  # 10ë°° ì¦ê°€
            "epochs": 500,        # 5ë°° ì¦ê°€
            "batch_size": 512,
            "lr": 0.0001,
            "depth": 7,           # ë§¤ìš° ê¹Šì€ íƒìƒ‰
            "iterations": 30      # ë§¤ìš° ë§ì€ ë°˜ë³µ
        }
    }
    
    config = time_configs[training_time]
    
    # methodê°€ ì§ì ‘ ì§€ì •ë˜ì—ˆëŠ”ì§€ í™•ì¸
    if method is not None:
        # ì§ì ‘ ì§€ì •ëœ method ì‚¬ìš©
        specified_method = method.lower()
        if specified_method not in ['gpu', 'cpu', 'gibo', 'hybrid']:
            print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” method: {method}. ìë™ ê°ì§€ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            method = None
        else:
            # method ìœ íš¨ì„± ê²€ì‚¬
            if specified_method == 'gpu' and not info.gpu_available:
                print("âš ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                specified_method = 'cpu'
            elif specified_method == 'hybrid' and not (use_gibo and info.has_gibo_files and info.gibo_file_count >= MIN_GIBO_FILES_FOR_TRAINING):
                print("âš ï¸ í˜¼í•© í•™ìŠµì„ ìœ„í•´ì„œëŠ” ê¸°ë³´ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤. GPU ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                specified_method = 'gpu' if info.gpu_available else 'cpu'
            elif specified_method == 'gibo' and not (use_gibo and info.has_gibo_files and info.gibo_file_count >= MIN_GIBO_FILES_FOR_TRAINING):
                print("âš ï¸ ê¸°ë³´ í•™ìŠµì„ ìœ„í•´ì„œëŠ” ê¸°ë³´ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                specified_method = 'cpu'
            
            method = specified_method
    
    # methodê°€ ì§€ì •ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ìë™ ê°ì§€
    if method is None:
        # GPU ê°€ìš© ì‹œ ë°°ì¹˜ ì‚¬ì´ì¦ˆ ë° í¬ì§€ì…˜ ìˆ˜ ì¦ê°€
        if info.gpu_available:
            method = "gpu"
            config = _adjust_config_for_gpu(config, info, training_time)
        else:
            method = "cpu"
            config = _adjust_config_for_cpu(config, info)
        
        # ê¸°ë³´ íŒŒì¼ ì‚¬ìš© ì—¬ë¶€
        should_use_gibo = use_gibo and info.has_gibo_files and info.gibo_file_count >= MIN_GIBO_FILES_FOR_TRAINING
        
        # Phase 3: í˜¼í•© í•™ìŠµ ì˜µì…˜ (ê¸°ë³´ íŒŒì¼ì´ ìˆê³ , GPUê°€ ìˆìœ¼ë©´ ê¶Œì¥)
        # í˜¼í•© í•™ìŠµì€ STANDARD ì´ìƒì˜ ì‹œê°„ì—ì„œë§Œ ì‚¬ìš© ê°€ëŠ¥
        use_hybrid = False
        if should_use_gibo and training_time in [
            TrainingTime.STANDARD, TrainingTime.DEEP, TrainingTime.INTENSIVE,
            TrainingTime.FULL, TrainingTime.EXTREME, TrainingTime.MARATHON
        ]:
            # GPUê°€ ìˆìœ¼ë©´ í˜¼í•© í•™ìŠµ ê¶Œì¥, ì—†ì–´ë„ ê°€ëŠ¥í•˜ì§€ë§Œ ëŠë¦¼
            use_hybrid = True
            method = "hybrid"
        elif should_use_gibo:
            method = "gibo" if not info.gpu_available else "gpu_gibo"
    else:
        # methodê°€ ì§ì ‘ ì§€ì •ëœ ê²½ìš°
        should_use_gibo = use_gibo and info.has_gibo_files and info.gibo_file_count >= MIN_GIBO_FILES_FOR_TRAINING
        
        # methodì— ë”°ë¼ ì„¤ì • ì¡°ì •
        if method == 'gpu' or method == 'hybrid':
            config = _adjust_config_for_gpu(config, info, training_time)
        else:
            config = _adjust_config_for_cpu(config, info)
        
        # use_hybrid ì„¤ì •
        use_hybrid = (method == 'hybrid')
    
    # ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •
    use_parallel = info.cpu_cores >= MIN_CPU_CORES_FOR_PARALLEL
    num_workers = max(1, min(info.cpu_cores - 1, MAX_WORKERS))
    
    # RAMì´ ì ìœ¼ë©´ ì„¤ì • ì¡°ì •
    if info.ram_gb < MIN_RAM_GB:
        config["positions"] = int(config["positions"] * RAM_POSITION_REDUCTION)
        config["batch_size"] = min(config["batch_size"], 128)
        num_workers = min(num_workers, MIN_WORKERS_LOW_RAM)
    
    # ë™ì  ì‹œê°„ ê³„ì‚°
    estimated_time = estimate_training_time(
        config=config,
        info=info,
        use_parallel=use_parallel,
        num_workers=num_workers,
        use_gibo=should_use_gibo,
        gibo_file_count=info.gibo_file_count if should_use_gibo else 0,
        use_hybrid=use_hybrid
    )
    
    return TrainingConfig(
        method=method,
        positions=int(config["positions"]),
        epochs=int(config["epochs"]),
        batch_size=int(config["batch_size"]),
        learning_rate=config["lr"],
        search_depth=config["depth"],
        iterations=config["iterations"],
        use_parallel=use_parallel,
        num_workers=num_workers,
        use_gibo=should_use_gibo,
        use_hybrid=use_hybrid,
        estimated_time_min=estimated_time
    )


def _adjust_config_for_gpu(
    config: Dict, info: SystemInfo, training_time: TrainingTime
) -> Dict:
    """GPU í™˜ê²½ì— ë§ê²Œ ì„¤ì • ì¡°ì •.
    
    Args:
        config: ê¸°ë³¸ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        info: ì‹œìŠ¤í…œ ì •ë³´
        training_time: í•™ìŠµ ì‹œê°„ ì˜µì…˜
        
    Returns:
        ì¡°ì •ëœ ì„¤ì • ë”•ì…”ë„ˆë¦¬
    """
    is_intensive_mode = training_time in [
        TrainingTime.FULL, 
        TrainingTime.EXTREME, 
        TrainingTime.MARATHON
    ]
    
    # GPU ë©”ëª¨ë¦¬ì— ë”°ë¼ ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì¡°ì •
    if info.gpu_memory_gb >= GPU_MEMORY_HIGH:
        config["batch_size"] = min(config["batch_size"] * 2, 1024)
        # FULL ì´ìƒ ëª¨ë“œì—ì„œëŠ” í¬ì§€ì…˜ ìˆ˜ë¥¼ ë” ë§ì´ ì¦ê°€
        if is_intensive_mode:
            config["positions"] = int(config["positions"] * GPU_POSITION_SCALE_HIGH_MEMORY_FULL)
        else:
            config["positions"] = int(config["positions"] * GPU_POSITION_SCALE_HIGH_MEMORY_NORMAL)
    elif info.gpu_memory_gb >= GPU_MEMORY_MEDIUM:
        config["batch_size"] = min(config["batch_size"] * 1.5, 512)
        if is_intensive_mode:
            config["positions"] = int(config["positions"] * GPU_POSITION_SCALE_MEDIUM_MEMORY)
    
    # estimated_minì€ ë‚˜ì¤‘ì— estimate_training_time í•¨ìˆ˜ì—ì„œ ê³„ì‚°ë˜ë¯€ë¡œ
    # ì—¬ê¸°ì„œëŠ” ì¡°ì •í•˜ì§€ ì•ŠìŒ (GPUëŠ” ìë™ìœ¼ë¡œ ì‹œê°„ ì¶”ì •ì— ë°˜ì˜ë¨)
    
    return config


def _adjust_config_for_cpu(config: Dict, info: SystemInfo) -> Dict:
    """CPU í™˜ê²½ì— ë§ê²Œ ì„¤ì • ì¡°ì •.
    
    Args:
        config: ê¸°ë³¸ ì„¤ì • ë”•ì…”ë„ˆë¦¬
        info: ì‹œìŠ¤í…œ ì •ë³´
        
    Returns:
        ì¡°ì •ëœ ì„¤ì • ë”•ì…”ë„ˆë¦¬
    """
    if info.cpu_cores >= MIN_CPU_CORES_FOR_PARALLEL:
        config["batch_size"] = min(config["batch_size"], 128)
    else:
        config["batch_size"] = min(config["batch_size"], 64)
        config["positions"] = int(config["positions"] * CPU_POSITION_REDUCTION_LOW_CORES)
    
    return config


def get_unique_output_path(base_path: str) -> str:
    """ì¤‘ë³µë˜ì§€ ì•ŠëŠ” ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ìƒì„±.
    
    Args:
        base_path: ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ (ì˜ˆ: "models/nnue_smart_model.json")
        
    Returns:
        ì¤‘ë³µë˜ì§€ ì•ŠëŠ” íŒŒì¼ ê²½ë¡œ (ì˜ˆ: "models/nnue_smart_model.json" ë˜ëŠ” 
        "models/nnue_smart_model_1.json")
    """
    if not os.path.exists(base_path):
        return base_path
    
    # íŒŒì¼ ê²½ë¡œ ë¶„ë¦¬
    directory = os.path.dirname(base_path)
    filename = os.path.basename(base_path)
    name, ext = os.path.splitext(filename)
    
    # ë²ˆí˜¸ë¥¼ ì¶”ê°€í•˜ì—¬ ì¤‘ë³µë˜ì§€ ì•ŠëŠ” íŒŒì¼ëª… ì°¾ê¸°
    counter = 1
    while True:
        new_filename = f"{name}_{counter}{ext}"
        new_path = os.path.join(directory, new_filename)
        if not os.path.exists(new_path):
            return new_path
        counter += 1


def print_training_config(config: TrainingConfig):
    """í•™ìŠµ ì„¤ì • ì¶œë ¥"""
    print("\n" + "=" * 60)
    print("âš™ï¸  í•™ìŠµ ì„¤ì •")
    print("=" * 60)
    
    method_names = {
        "gpu": "GPU ê°€ì† í•™ìŠµ",
        "cpu": "CPU í•™ìŠµ",
        "gibo": "ê¸°ë³´ ê¸°ë°˜ í•™ìŠµ (CPU)",
        "gpu_gibo": "ê¸°ë³´ ê¸°ë°˜ í•™ìŠµ (GPU)",
        "hybrid": "í˜¼í•© í•™ìŠµ (ê¸°ë³´ + Self-play)"  # Phase 3
    }
    
    print(f"\nğŸ“‹ í•™ìŠµ ë°©ì‹: {method_names.get(config.method, config.method)}")
    print(f"ğŸ“‹ í•™ìŠµ í¬ì§€ì…˜ ìˆ˜: {config.positions:,}ê°œ")
    print(f"ğŸ“‹ ì—í¬í¬ ìˆ˜: {config.epochs}íšŒ")
    print(f"ğŸ“‹ ë°°ì¹˜ ì‚¬ì´ì¦ˆ: {config.batch_size}")
    print(f"ğŸ“‹ í•™ìŠµë¥ : {config.learning_rate}")
    print(f"ğŸ“‹ íƒìƒ‰ ê¹Šì´: {config.search_depth}")
    
    if config.iterations > 1:
        print(f"ğŸ“‹ ë°˜ë³µ í•™ìŠµ: {config.iterations}íšŒ")
    
    if config.use_parallel:
        print(f"ğŸ“‹ ë³‘ë ¬ ì²˜ë¦¬: {config.num_workers}ê°œ ì›Œì»¤")
    
    if config.use_gibo:
        print("ğŸ“‹ ê¸°ë³´ ë°ì´í„° í™œìš©: âœ…")
    
    if config.use_hybrid:
        print("ğŸ“‹ í˜¼í•© í•™ìŠµ ëª¨ë“œ: âœ… (ê¸°ë³´ â†’ Self-play â†’ Fine-tuning)")
        print(f"   - ê° iterationë§ˆë‹¤: ê¸°ë³´ í•™ìŠµ â†’ Self-play í•™ìŠµ â†’ Fine-tuning â†’ í‰ê°€")
    
    print(f"\nâ±ï¸  ì˜ˆìƒ í•™ìŠµ ì‹œê°„: ì•½ {config.estimated_time_min}ë¶„")


def interactive_menu(info: SystemInfo) -> Tuple[TrainingTime, bool, Optional[str], Optional[str]]:
    """ëŒ€í™”í˜• ë©”ë‰´
    
    Returns:
        (training_time, use_gibo, load_model, method)
    """
    print("\n" + "=" * 60)
    print("ğŸ¯ í•™ìŠµ ì‹œê°„ ì„ íƒ")
    print("=" * 60)
    
    options = [
        (TrainingTime.QUICK, "âš¡ ë¹ ë¥¸ í•™ìŠµ", "~5ë¶„", "ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©, ê¸°ë³¸ì ì¸ í•™ìŠµ"),
        (TrainingTime.STANDARD, "ğŸ“˜ í‘œì¤€ í•™ìŠµ", "~15ë¶„", "ì¼ë°˜ì ì¸ ì‚¬ìš©ì— ì í•©"),
        (TrainingTime.DEEP, "ğŸ“— ê¹Šì€ í•™ìŠµ", "~30ë¶„", "ë” ë‚˜ì€ ì„±ëŠ¥, ê¶Œì¥"),
        (TrainingTime.INTENSIVE, "ğŸ“• ì§‘ì¤‘ í•™ìŠµ", "~1ì‹œê°„", "ë†’ì€ ì„±ëŠ¥ ëª©í‘œ"),
        (TrainingTime.FULL, "ğŸ† ì™„ì „ í•™ìŠµ", "~3ì‹œê°„", "ìµœê³  ì„±ëŠ¥, ê°•í™”ëœ ì„¤ì •"),
        (TrainingTime.EXTREME, "ğŸ”¥ ê·¹í•œ í•™ìŠµ", "~4ì‹œê°„", "ìµœê°• ì„±ëŠ¥, ë§¤ìš° ê¸´ í•™ìŠµ"),
        (TrainingTime.MARATHON, "ğŸƒ ë§ˆë¼í†¤ í•™ìŠµ", "~8ì‹œê°„", "ìµœì¢… ë³´ìŠ¤, í•˜ë£¨ ì¢…ì¼ í•™ìŠµ"),
    ]
    
    print("\ní•™ìŠµ ì‹œê°„ì„ ì„ íƒí•˜ì„¸ìš”:\n")
    for i, (_, name, time_est, desc) in enumerate(options, 1):
        print(f"  {i}. {name} ({time_est})")
        print(f"     â””â”€ {desc}")
    
    print("\n  0. ì¢…ë£Œ")
    
    while True:
        try:
            choice = input("\nì„ íƒ (1-7, 0=ì¢…ë£Œ): ").strip()
            if choice == "0":
                return None, False, None
            
            idx = int(choice) - 1
            if 0 <= idx < len(options):
                selected_time = options[idx][0]
                break
            print(f"âŒ 1-{len(options)} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        except ValueError:
            print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    
    # í•™ìŠµ ë°©ë²• ì„ íƒ
    print("\n" + "=" * 60)
    print("ğŸ”§ í•™ìŠµ ë°©ë²• ì„ íƒ (ì„ íƒ ì‚¬í•­)")
    print("=" * 60)
    print("\ní•™ìŠµ ë°©ë²•ì„ ì§ì ‘ ì„ íƒí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ìë™ ê°ì§€ë„ ê°€ëŠ¥)")
    print("  1. ìë™ ê°ì§€ (ê¶Œì¥)")
    print("  2. GPU í•™ìŠµ")
    print("  3. CPU í•™ìŠµ")
    if info.has_gibo_files and info.gibo_file_count >= MIN_GIBO_FILES_FOR_TRAINING:
        print("  4. ê¸°ë³´ í•™ìŠµ")
        if info.gpu_available:
            print("  5. í˜¼í•© í•™ìŠµ (ê¸°ë³´ + Self-play)")
    
    method = None
    while True:
        try:
            method_choice = input("\nì„ íƒ (1-5, Enter=ìë™): ").strip()
            if not method_choice or method_choice == '1':
                method = None  # ìë™ ê°ì§€
                break
            elif method_choice == '2':
                if info.gpu_available:
                    method = 'gpu'
                    break
                else:
                    print("âŒ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”.")
            elif method_choice == '3':
                method = 'cpu'
                break
            elif method_choice == '4':
                if info.has_gibo_files and info.gibo_file_count >= MIN_GIBO_FILES_FOR_TRAINING:
                    method = 'gibo'
                    break
                else:
                    print("âŒ ê¸°ë³´ íŒŒì¼ì´ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”.")
            elif method_choice == '5':
                if info.has_gibo_files and info.gibo_file_count >= MIN_GIBO_FILES_FOR_TRAINING:
                    method = 'hybrid'
                    break
                else:
                    print("âŒ í˜¼í•© í•™ìŠµì„ ìœ„í•´ì„œëŠ” ê¸°ë³´ íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ë°©ë²•ì„ ì„ íƒí•˜ì„¸ìš”.")
            else:
                print("âŒ 1-5 ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        except (ValueError, KeyboardInterrupt):
            method = None
            break
    
    # ê¸°ë³´ ì‚¬ìš© ì—¬ë¶€
    use_gibo = False
    if info.has_gibo_files:
        print(f"\nê¸°ë³´ íŒŒì¼ {info.gibo_file_count}ê°œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
        gibo_choice = input("ê¸°ë³´ ë°ì´í„°ë¥¼ í•™ìŠµì— í™œìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Y/n): ").strip().lower()
        use_gibo = gibo_choice != 'n'
    
    # ê¸°ì¡´ ëª¨ë¸ ë¡œë“œ ì—¬ë¶€
    load_model = None
    existing_models = sorted(glob.glob("models/*.json"))  # ì •ë ¬í•˜ì—¬ ì¼ê´€ëœ ìˆœì„œ ë³´ì¥
    if existing_models:
        print(f"\nê¸°ì¡´ ëª¨ë¸ {len(existing_models)}ê°œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
        for i, model in enumerate(existing_models, 1):
            print(f"  {i}. {os.path.basename(model)}")
        
        load_choice = input("\nê¸°ì¡´ ëª¨ë¸ì—ì„œ ê³„ì† í•™ìŠµí•˜ì‹œê² ìŠµë‹ˆê¹Œ? (ìˆ«ì ì…ë ¥ ë˜ëŠ” n): ").strip().lower()
        if load_choice != 'n' and load_choice.isdigit():
            idx = int(load_choice) - 1
            if 0 <= idx < len(existing_models):
                load_model = existing_models[idx]
    
    return selected_time, use_gibo, load_model, method


def train_with_gpu(config: TrainingConfig, load_model: Optional[str] = None, gibo_dir: str = "gibo"):
    """GPU ê°€ì† í•™ìŠµ ì‹¤í–‰"""
    try:
        import torch
        from janggi.nnue_torch import NNUETorch, FeatureExtractor, GPUTrainer, get_device
        from scripts.train_nnue_gpu import get_optimal_batch_size
    except ImportError as e:
        print(f"âŒ PyTorchê°€ í•„ìš”í•©ë‹ˆë‹¤: {e}")
        print("ì„¤ì¹˜: pip install torch")
        return None
    
    device = get_device()
    print(f"\nğŸš€ GPU í•™ìŠµ ì‹œì‘ (Device: {device})")
    
    # GPU ë©”ëª¨ë¦¬ ê¸°ë°˜ ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚°
    eval_batch_size = get_optimal_batch_size(device=device)
    if device.type == 'cuda':
        print(f"ğŸ“Š GPU ë©”ëª¨ë¦¬ ê¸°ë°˜ ìµœì  í‰ê°€ ë°°ì¹˜ í¬ê¸°: {eval_batch_size}")
    
    # ëª¨ë¸ ì´ˆê¸°í™” ë˜ëŠ” ë¡œë“œ
    if load_model:
        print(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ: {load_model}")
        nnue = NNUETorch.from_file(load_model, device=device)
    else:
        print("ğŸ†• ìƒˆ ëª¨ë¸ ì´ˆê¸°í™”")
        nnue = NNUETorch(device=device)
    
    # Phase 3: í˜¼í•© í•™ìŠµ ëª¨ë“œ
    if config.use_hybrid:
        try:
            from scripts.train_nnue_hybrid import hybrid_training
            
            print("\nğŸ”„ í˜¼í•© í•™ìŠµ ëª¨ë“œ ì‹œì‘ (ê¸°ë³´ â†’ Self-play â†’ Fine-tuning)")
            
            # í˜¼í•© í•™ìŠµ íŒŒë¼ë¯¸í„° ê³„ì‚°
            # iterationsëŠ” config.iterations ì‚¬ìš©
            # ê° iterationì˜ epoch ìˆ˜ë¥¼ ì ì ˆíˆ ë¶„ë°°
            gibo_epochs = max(1, config.epochs // (config.iterations * 4))  # ì „ì²´ì˜ 1/4
            selfplay_epochs = max(5, config.epochs // (config.iterations * 2))  # ì „ì²´ì˜ 1/2
            fine_tune_epochs = max(1, config.epochs // (config.iterations * 4))  # ì „ì²´ì˜ 1/4
            
            # Self-play ê²Œì„ ìˆ˜ ê³„ì‚° (ì „ì²´ positionsë¥¼ iterationsë¡œ ë‚˜ëˆ”)
            positions_per_iteration = config.positions // config.iterations
            selfplay_games = max(50, positions_per_iteration // 80)  # ê²Œì„ë‹¹ í‰ê·  80ê°œ í¬ì§€ì…˜ ê°€ì •
            
            print(f"   ì„¤ì •:")
            print(f"   - ë°˜ë³µ íšŸìˆ˜: {config.iterations}íšŒ")
            print(f"   - ê¸°ë³´ í•™ìŠµ: {gibo_epochs} epochs/iteration")
            print(f"   - Self-play í•™ìŠµ: {selfplay_epochs} epochs/iteration (~{selfplay_games} games)")
            print(f"   - Fine-tuning: {fine_tune_epochs} epochs/iteration")
            
            # í˜¼í•© í•™ìŠµ ì‹¤í–‰
            nnue = hybrid_training(
                gibo_dir=gibo_dir,
                nnue=nnue,
                iterations=config.iterations,
                gibo_epochs=gibo_epochs,
                selfplay_epochs=selfplay_epochs,
                fine_tune_epochs=fine_tune_epochs,
                selfplay_games=selfplay_games,
                batch_size=config.batch_size,
                learning_rate=config.learning_rate,
                positions_per_game=50,
                search_depth=config.search_depth,
                output_dir="models",
                use_parallel=config.use_parallel,
                num_workers=config.num_workers if config.use_parallel else None,
                eval_batch_size=eval_batch_size,
                eval_num_workers=config.num_workers if config.use_parallel else None
            )
            
            history = {"train_loss": [], "val_loss": []}  # í˜¼í•© í•™ìŠµì€ ë³„ë„ ì¶œë ¥
            
        except ImportError as e:
            print(f"âš ï¸ í˜¼í•© í•™ìŠµ ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            print("   ì¼ë°˜ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            config.use_hybrid = False
        except Exception as e:
            print(f"âš ï¸ í˜¼í•© í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            print("   ì¼ë°˜ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            config.use_hybrid = False
    
    # ê¸°ë³´ ê¸°ë°˜ í•™ìŠµ (í˜¼í•© í•™ìŠµì´ ì•„ë‹ ë•Œë§Œ)
    if config.use_gibo and not config.use_hybrid:
        from scripts.train_nnue_gibo import GibParser, GiboDataGenerator, train_with_gradient_clipping
        
        print("\nğŸ“š ê¸°ë³´ íŒŒì¼ íŒŒì‹± ì¤‘...")
        parser = GibParser()
        games = parser.parse_directory(gibo_dir)
        
        if games:
            print(f"âœ… {len(games)}ê°œ ê²Œì„ ë¡œë“œ ì™„ë£Œ")
            
            generator = GiboDataGenerator()
            
            # ë³‘ë ¬ ì²˜ë¦¬ ì‚¬ìš© (CPU ì½”ì–´ê°€ 4ê°œ ì´ìƒì´ê³  ê²Œì„ì´ ë§ìœ¼ë©´ ìë™ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬)
            import multiprocessing as mp
            cpu_count = mp.cpu_count()
            use_parallel = config.use_parallel and len(games) > 100
            
            if use_parallel:
                print(f"ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ ëª¨ë“œ ì‚¬ìš© ({config.num_workers}ê°œ ì›Œì»¤)")
                features, targets = generator.generate_from_games_parallel(
                    games,
                    positions_per_game=50,
                    num_workers=config.num_workers,
                    progress_callback=lambda d, t: print(f"\rì²˜ë¦¬ ì¤‘: {d}/{t}", end="", flush=True)
                )
            else:
                print("ğŸ”„ ìˆœì°¨ ì²˜ë¦¬ ëª¨ë“œ ì‚¬ìš©")
                features, targets = generator.generate_from_games(
                    games,
                    positions_per_game=50,
                    progress_callback=lambda d, t: print(f"\rì²˜ë¦¬ ì¤‘: {d}/{t}", end="", flush=True)
                )
            print()
            
            print(f"\nğŸ“ ê¸°ë³´ ê¸°ë°˜ í•™ìŠµ ì‹œì‘ ({len(features)}ê°œ í¬ì§€ì…˜)...")
            train_with_gradient_clipping(
                nnue, features, targets,
                epochs=config.epochs // 2,
                batch_size=config.batch_size,
                learning_rate=config.learning_rate
            )
    
    # ë°˜ë³µ í•™ìŠµ ì‚¬ìš© ì—¬ë¶€ ê²°ì • (í˜¼í•© í•™ìŠµì´ ì•„ë‹ ë•Œë§Œ)
    if config.iterations > 1 and not config.use_hybrid:
        # ë°˜ë³µ í•™ìŠµ ëª¨ë“œ
        from scripts.train_nnue_gpu import train_iterative
        
        print(f"\nğŸ”„ ë°˜ë³µ í•™ìŠµ ëª¨ë“œ ({config.iterations}íšŒ ë°˜ë³µ)")
        # ê²Œì„ë‹¹ ì•½ 50-100ê°œ í¬ì§€ì…˜ì´ ìƒì„±ë˜ë¯€ë¡œ, ê²Œì„ ìˆ˜ ê³„ì‚°
        positions_per_iteration = config.positions // config.iterations
        games_per_iteration = max(50, positions_per_iteration // 80)  # ê²Œì„ë‹¹ í‰ê·  80ê°œ í¬ì§€ì…˜ ê°€ì •
        epochs_per_iteration = max(10, config.epochs // config.iterations)
        
        print(f"   ê° ë°˜ë³µë§ˆë‹¤: ~{games_per_iteration}ê²Œì„ (~{positions_per_iteration:,}ê°œ í¬ì§€ì…˜), {epochs_per_iteration}íšŒ ì—í¬í¬")
        
        # ë°˜ë³µ í•™ìŠµ ì‹¤í–‰ (ë³‘ë ¬ self-play + GPU ë°°ì¹˜ í‰ê°€ ì‚¬ìš©)
        train_iterative(
            nnue,
            num_iterations=config.iterations,
            games_per_iteration=games_per_iteration,
            epochs_per_iteration=epochs_per_iteration,
            batch_size=config.batch_size,
            output_dir="models",
            search_depth=config.search_depth,
            use_parallel=True,  # ë³‘ë ¬ self-play ì‚¬ìš©
            num_workers=config.num_workers if config.use_parallel else None,
            eval_batch_size=eval_batch_size,  # GPU ë°°ì¹˜ í‰ê°€ í¬ê¸°
            eval_num_workers=config.num_workers if config.use_parallel else None,
            base_learning_rate=config.learning_rate  # configì˜ learning_rate ì‚¬ìš©
        )
        
        history = {"train_loss": [], "val_loss": []}  # ë°˜ë³µ í•™ìŠµì€ ë³„ë„ ì¶œë ¥
    else:
        # ë‹¨ì¼ í•™ìŠµ ëª¨ë“œ
        from scripts.train_nnue_gpu import DataGenerator
        
        generator = DataGenerator()
        
        def progress(done, total, speed, eta):
            print(f"\rğŸ“Š í¬ì§€ì…˜ ìƒì„±: {done:,}/{total:,} ({speed:.1f}/s, ETA: {eta:.0f}s)", end="", flush=True)
        
        print(f"\nğŸ² Self-play í¬ì§€ì…˜ ìƒì„± ì¤‘ ({config.positions:,}ê°œ)...")
        
        if config.use_parallel:
            features, targets = generator.generate_positions_parallel(
                num_positions=config.positions,
                num_workers=config.num_workers,
                progress_callback=progress
            )
        else:
            features, targets = generator.generate_positions_fast(
                num_positions=config.positions,
                progress_callback=progress
            )
        
        print()  # ì¤„ë°”ê¿ˆ
        
        print(f"\nğŸ“ í•™ìŠµ ì‹œì‘ ({len(features):,}ê°œ í¬ì§€ì…˜, {config.epochs}íšŒ ì—í¬í¬)...")
        trainer = GPUTrainer(nnue)
        
        history = trainer.train(
            features, targets,
            epochs=config.epochs,
            batch_size=config.batch_size,
            learning_rate=config.learning_rate,
            early_stopping_patience=10
        )
    
    # ëª¨ë¸ ì €ì¥
    os.makedirs("models", exist_ok=True)
    if config.use_hybrid:
        base_path = "models/nnue_smart_hybrid_model.json"
    else:
        base_path = "models/nnue_smart_model.json"
    output_path = get_unique_output_path(base_path)
    nnue.save(output_path)
    print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥: {output_path}")
    
    return nnue, history, output_path


def train_with_cpu(config: TrainingConfig, load_model: Optional[str] = None, gibo_dir: str = "gibo"):
    """CPU í•™ìŠµ ì‹¤í–‰"""
    from janggi.nnue import NNUE
    from scripts.train_nnue import TrainingDataGenerator, NNUETrainer, IterativeTrainer
    
    print("\nğŸ–¥ï¸  CPU í•™ìŠµ ì‹œì‘")
    
    # ëª¨ë¸ ì´ˆê¸°í™” ë˜ëŠ” ë¡œë“œ
    if load_model:
        print(f"ğŸ“‚ ëª¨ë¸ ë¡œë“œ: {load_model}")
        nnue = NNUE.from_file(load_model)
    else:
        print("ğŸ†• ìƒˆ ëª¨ë¸ ì´ˆê¸°í™”")
        nnue = NNUE()
    
    # ë°˜ë³µ í•™ìŠµ ì‚¬ìš©
    if config.iterations > 1:
        print(f"\nğŸ”„ ë°˜ë³µ í•™ìŠµ ëª¨ë“œ ({config.iterations}íšŒ)")
        trainer = IterativeTrainer(nnue)
        trainer.run_iterations(
            num_iterations=config.iterations,
            games_per_iteration=config.positions // (50 * config.iterations),
            search_depth=config.search_depth,
            epochs_per_iteration=config.epochs // config.iterations,
            output_dir="models",
            base_name="nnue_smart_iter"
        )
    else:
        # ë‹¨ì¼ í•™ìŠµ
        print(f"\nğŸ² í¬ì§€ì…˜ ìƒì„± ì¤‘ ({config.positions}ê°œ)...")
        generator = TrainingDataGenerator(search_depth=config.search_depth)
        
        boards, targets = generator.generate_diverse_positions(
            num_positions=config.positions,
            search_depth=config.search_depth,
            progress_callback=lambda c, t: print(f"\rğŸ“Š í¬ì§€ì…˜: {c}/{t}", end="", flush=True)
        )
        print()
        
        print(f"\nğŸ“ í•™ìŠµ ì‹œì‘ ({len(boards)}ê°œ í¬ì§€ì…˜)...")
        trainer = NNUETrainer(nnue)
        history = trainer.train(
            boards, targets,
            epochs=config.epochs,
            learning_rate=config.learning_rate,
            batch_size=config.batch_size
        )
    
    # ëª¨ë¸ ì €ì¥
    os.makedirs("models", exist_ok=True)
    base_path = "models/nnue_smart_model.json"
    output_path = get_unique_output_path(base_path)
    nnue.save(output_path)
    print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥: {output_path}")
    
    return nnue, output_path


def evaluate_model(model, num_games: int = 5):
    """ëª¨ë¸ í‰ê°€ (GPU ë°°ì¹˜ í‰ê°€ ìµœì í™” ì‚¬ìš©)"""
    print(f"\nğŸ“ˆ ëª¨ë¸ í‰ê°€ ì¤‘ ({num_games}ê²Œì„)...")
    
    try:
        from scripts.train_nnue_gpu import evaluate_model as gpu_eval, get_optimal_batch_size
        from janggi.nnue_torch import get_device
        
        # GPU ë°°ì¹˜ í‰ê°€ ìµœì í™” ì‚¬ìš©
        device = get_device()
        eval_batch_size = get_optimal_batch_size(device=device)
        
        # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ë³‘ë ¬ í‰ê°€ + ë°°ì¹˜ í‰ê°€ ì‚¬ìš©
        use_gpu = device.type == 'cuda'
        if use_gpu:
            # ì‘ì€ ê²Œì„ ìˆ˜ì— ëŒ€í•´ ì›Œì»¤ ìˆ˜ ì œí•œ (ë©€í‹°í”„ë¡œì„¸ì‹± ì˜¤ë²„í—¤ë“œ ê°ì†Œ)
            # ì‘ì€ ê²Œì„ ìˆ˜ì—ì„œëŠ” ì›Œì»¤ ì´ˆê¸°í™” + ëª¨ë¸ ë¡œë“œ ì˜¤ë²„í—¤ë“œê°€ ë³‘ë ¬í™” ì´ì ë³´ë‹¤ í¼
            if num_games <= 5:
                num_workers = 1
            elif num_games <= 10:
                num_workers = min(2, num_games)
            else:
                num_workers = max(1, min(mp.cpu_count() - 1, num_games))
        else:
            num_workers = None
        
        win_rate = gpu_eval(
            model, 
            num_games=num_games,
            search_depth=3,
            num_workers=num_workers,
            use_gpu=use_gpu,
            eval_batch_size=eval_batch_size
        )
    except Exception as e:
        # CPU ëª¨ë¸ í‰ê°€ (fallback)
        print(f"âš ï¸ GPU í‰ê°€ ì‹¤íŒ¨, CPU í‰ê°€ë¡œ ì „í™˜: {e}")
        from janggi.board import Board, Side
        from janggi.engine import Engine
        
        wins = 0
        engine = Engine(depth=2, use_nnue=True)
        engine.nnue = model
        
        for _ in range(num_games):
            board = Board()
            for _ in range(100):
                if board.is_checkmate() or board.is_stalemate():
                    break
                move = engine.search(board)
                if move is None:
                    break
                board.make_move(move)
            
            if board.is_checkmate() and board.side_to_move == Side.HAN:
                wins += 1
        
        win_rate = wins / num_games
    
    print(f"âœ… SimpleEvaluator ëŒ€ë¹„ ìŠ¹ë¥ : {win_rate:.1%}")
    return win_rate


def main():
    parser = argparse.ArgumentParser(
        description='Smart NNUE Training - ìë™ í™˜ê²½ ê°ì§€ ë° ìµœì í™” í•™ìŠµ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
í•™ìŠµ ì‹œê°„ ì˜µì…˜:
  quick      âš¡ ë¹ ë¥¸ í•™ìŠµ (~5ë¶„)    - ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©
  standard   ğŸ“˜ í‘œì¤€ í•™ìŠµ (~15ë¶„)   - ì¼ë°˜ì ì¸ ì‚¬ìš©
  deep       ğŸ“— ê¹Šì€ í•™ìŠµ (~30ë¶„)   - ê¶Œì¥
  intensive  ğŸ“• ì§‘ì¤‘ í•™ìŠµ (~1ì‹œê°„)  - ë†’ì€ ì„±ëŠ¥
  full       ğŸ† ì™„ì „ í•™ìŠµ (~3ì‹œê°„)  - ìµœê³  ì„±ëŠ¥, ê°•í™”ëœ ì„¤ì •
  extreme    ğŸ”¥ ê·¹í•œ í•™ìŠµ (~4ì‹œê°„)  - ìµœê°• ì„±ëŠ¥
  marathon   ğŸƒ ë§ˆë¼í†¤ í•™ìŠµ (~8ì‹œê°„) - ìµœì¢… ë³´ìŠ¤

ì˜ˆì‹œ:
  python smart_train.py                      # ëŒ€í™”í˜• ëª¨ë“œ
  python smart_train.py --time standard      # í‘œì¤€ í•™ìŠµ
  python smart_train.py --time deep --no-gibo  # ê¸°ë³´ ì—†ì´ ê¹Šì€ í•™ìŠµ
        """
    )
    
    parser.add_argument('--time', type=str, 
                        choices=['quick', 'standard', 'deep', 'intensive', 'full', 'extreme', 'marathon'],
                        default=None,
                        help='í•™ìŠµ ì‹œê°„ ì„ íƒ')
    parser.add_argument('--load', type=str, default=None,
                        help='ê¸°ì¡´ ëª¨ë¸ íŒŒì¼ ë¡œë“œ')
    parser.add_argument('--no-gibo', action='store_true',
                        help='ê¸°ë³´ íŒŒì¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ')
    parser.add_argument('--gibo-dir', type=str, default='gibo',
                        help='ê¸°ë³´ íŒŒì¼ ë””ë ‰í† ë¦¬')
    parser.add_argument('--method', type=str,
                        choices=['gpu', 'cpu', 'gibo', 'hybrid'],
                        default=None,
                        help='í•™ìŠµ ë°©ë²• ì§ì ‘ ì§€ì • (gpu, cpu, gibo, hybrid). ì§€ì •í•˜ì§€ ì•Šìœ¼ë©´ ìë™ ê°ì§€')
    parser.add_argument('--output', type=str, default='models/nnue_smart_model.json',
                        help='ì¶œë ¥ ëª¨ë¸ íŒŒì¼')
    parser.add_argument('--skip-eval', action='store_true',
                        help='í•™ìŠµ í›„ í‰ê°€ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--info-only', action='store_true',
                        help='ì‹œìŠ¤í…œ ì •ë³´ë§Œ ì¶œë ¥í•˜ê³  ì¢…ë£Œ')
    
    args = parser.parse_args()
    
    # ì‹œìŠ¤í…œ ì •ë³´ ìˆ˜ì§‘
    print("\nğŸ” ì‹œìŠ¤í…œ í™˜ê²½ ë¶„ì„ ì¤‘...")
    info = get_system_info(args.gibo_dir)
    print_system_info(info)
    
    if args.info_only:
        return
    
    # í•™ìŠµ ì‹œê°„ ì„ íƒ
    if args.time:
        training_time = TrainingTime(args.time)
        use_gibo = not args.no_gibo and info.has_gibo_files
        load_model = args.load
        method = args.method
    else:
        # ëŒ€í™”í˜• ë©”ë‰´
        result = interactive_menu(info)
        if result[0] is None:
            print("\nğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        training_time, use_gibo, load_model, method = result
    
    # í•™ìŠµ ì„¤ì • ê³„ì‚°
    config = get_training_config(info, training_time, use_gibo, method=method)
    print_training_config(config)
    
    # í™•ì¸
    if not args.time:  # ëŒ€í™”í˜• ëª¨ë“œì—ì„œë§Œ í™•ì¸
        confirm = input("\nì´ ì„¤ì •ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Y/n): ").strip().lower()
        if confirm == 'n':
            print("ğŸ‘‹ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return
    
    # í•™ìŠµ ì‹œì‘
    print("\n" + "=" * 60)
    print("ğŸ“ í•™ìŠµ ì‹œì‘")
    print("=" * 60)
    
    start_time = time.time()
    
    output_path = None
    if config.method in ["gpu", "gpu_gibo", "hybrid"]:
        result = train_with_gpu(config, load_model, args.gibo_dir)
        if result:
            model, history, output_path = result
    else:
        model, output_path = train_with_cpu(config, load_model, args.gibo_dir)
    
    elapsed = time.time() - start_time
    print(f"\nâ±ï¸  ì´ í•™ìŠµ ì‹œê°„: {elapsed/60:.1f}ë¶„")
    
    # ëª¨ë¸ í‰ê°€
    if not args.skip_eval and model:
        try:
            evaluate_model(model)
        except Exception as e:
            print(f"âš ï¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    print("\n" + "=" * 60)
    print("âœ… í•™ìŠµ ì™„ë£Œ!")
    print("=" * 60)
    
    if output_path:
        print(f"\nëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {output_path}")
        print("\nì‚¬ìš©ë²•:")
        if config.method in ["gpu", "gpu_gibo", "hybrid"]:
            print("  from janggi.nnue_torch import NNUETorch")
            print(f"  nnue = NNUETorch.from_file('{output_path}')")
        else:
            print("  from janggi.nnue import NNUE")
            print(f"  nnue = NNUE.from_file('{output_path}')")


if __name__ == "__main__":
    main()

